{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from generator import Generator\n",
    "from discriminator import Discriminator\n",
    "from dataset import AppleOrangeData\n",
    "from trainer import train_models\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device agnostic code\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "\n",
    "TRAIN_DIR = 'apple_orange_data/train'\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 2e-4\n",
    "CYCLE_LAMBDA = 10\n",
    "NUM_EPOCHS = 64\n",
    "\n",
    "GENERATOR_G_SAVE_PATH = 'Models/generator_g.pth.tar'\n",
    "GENERATOR_H_SAVE_PATH = 'Models/generator_h.pth.tar'\n",
    "DISCRIMINATOR_X_SAVE_PATH = 'Models/discriminator_x.pth.tar'\n",
    "DISCRIMINATOR_Y_SAVE_PATH = 'Models/discriminator_y.pth.tar'\n",
    "RESULT_SAVE_PATH = 'Results/Train 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1019, 1019)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(size=(256, 256)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "train_data = AppleOrangeData(root_dir=TRAIN_DIR, transform=input_transform)\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "len(train_data), len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising models \n",
    "\n",
    "generator_G = Generator(in_channels=3, out_channels=3, num_features=64, num_residuals=9).to(device)\n",
    "generator_H = Generator(in_channels=3, out_channels=3, num_features=64, num_residuals=9).to(device)\n",
    "discriminator_X = Discriminator(in_channels=3).to(device)\n",
    "discriminator_Y = Discriminator(in_channels=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Exists\n",
      "2) Exists\n",
      "3) Exists\n",
      "4) Exists\n"
     ]
    }
   ],
   "source": [
    "# Loading model if exists\n",
    "\n",
    "model_file = Path(GENERATOR_G_SAVE_PATH)\n",
    "if model_file.is_file():\n",
    "    generator_G.load_state_dict(torch.load(f=GENERATOR_G_SAVE_PATH))\n",
    "    print(\"1) Exists\")\n",
    "else:\n",
    "    print(\"1) Created\")\n",
    "\n",
    "model_file = Path(GENERATOR_H_SAVE_PATH)\n",
    "if model_file.is_file():\n",
    "    generator_H.load_state_dict(torch.load(f=GENERATOR_H_SAVE_PATH))\n",
    "    print(\"2) Exists\")\n",
    "else:\n",
    "    print(\"2) Created\")\n",
    "    \n",
    "model_file = Path(DISCRIMINATOR_X_SAVE_PATH)\n",
    "if model_file.is_file():\n",
    "    discriminator_X.load_state_dict(torch.load(f=DISCRIMINATOR_X_SAVE_PATH))\n",
    "    print(\"3) Exists\")\n",
    "else:\n",
    "    print(\"3) Created\")\n",
    "    \n",
    "model_file = Path(DISCRIMINATOR_Y_SAVE_PATH)\n",
    "if model_file.is_file():\n",
    "    discriminator_Y.load_state_dict(torch.load(f=DISCRIMINATOR_Y_SAVE_PATH))\n",
    "    print(\"4) Exists\")\n",
    "else:\n",
    "    print(\"4) Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions and optimizers \n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "l1_loss = nn.L1Loss()\n",
    "gen_optimizer = torch.optim.Adam(params=list(generator_G.parameters())+list(generator_H.parameters()), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "disc_optimizer = torch.optim.Adam(params=list(discriminator_X.parameters())+list(discriminator_Y.parameters()), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "gen_scaler = torch.cuda.amp.GradScaler()\n",
    "disc_scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/64]: 100%|██████████| 1019/1019 [19:54<00:00,  1.17s/it, Gen batch loss=3.51, Gen train loss=3.88, Disc batch loss=0.621, Disc train loss=0.638]\n",
      "Epoch [25/64]: 100%|██████████| 1019/1019 [19:54<00:00,  1.17s/it, Gen batch loss=4.13, Gen train loss=3.89, Disc batch loss=1.05, Disc train loss=0.644] \n",
      "Epoch [26/64]: 100%|██████████| 1019/1019 [19:55<00:00,  1.17s/it, Gen batch loss=4.07, Gen train loss=3.81, Disc batch loss=0.764, Disc train loss=0.653]\n",
      "Epoch [27/64]: 100%|██████████| 1019/1019 [19:51<00:00,  1.17s/it, Gen batch loss=3.17, Gen train loss=3.88, Disc batch loss=1.03, Disc train loss=0.615] \n",
      "Epoch [28/64]: 100%|██████████| 1019/1019 [19:51<00:00,  1.17s/it, Gen batch loss=3.33, Gen train loss=3.82, Disc batch loss=0.361, Disc train loss=0.619]\n",
      "Epoch [29/64]: 100%|██████████| 1019/1019 [19:53<00:00,  1.17s/it, Gen batch loss=3.06, Gen train loss=3.77, Disc batch loss=1.32, Disc train loss=0.628] \n",
      "Epoch [30/64]: 100%|██████████| 1019/1019 [19:52<00:00,  1.17s/it, Gen batch loss=2.84, Gen train loss=3.75, Disc batch loss=0.638, Disc train loss=0.623]\n",
      "Epoch [31/64]: 100%|██████████| 1019/1019 [19:52<00:00,  1.17s/it, Gen batch loss=3.63, Gen train loss=3.73, Disc batch loss=0.583, Disc train loss=0.613]\n",
      "Epoch [32/64]: 100%|██████████| 1019/1019 [19:54<00:00,  1.17s/it, Gen batch loss=3.4, Gen train loss=3.7, Disc batch loss=0.902, Disc train loss=0.613]  \n",
      "Epoch [33/64]: 100%|██████████| 1019/1019 [19:52<00:00,  1.17s/it, Gen batch loss=3.16, Gen train loss=3.68, Disc batch loss=0.558, Disc train loss=0.614]\n",
      "Epoch [34/64]: 100%|██████████| 1019/1019 [19:49<00:00,  1.17s/it, Gen batch loss=3.84, Gen train loss=3.65, Disc batch loss=0.282, Disc train loss=0.603]\n",
      "Epoch [35/64]: 100%|██████████| 1019/1019 [19:51<00:00,  1.17s/it, Gen batch loss=3.67, Gen train loss=3.71, Disc batch loss=0.757, Disc train loss=0.607]\n",
      "Epoch [36/64]: 100%|██████████| 1019/1019 [19:53<00:00,  1.17s/it, Gen batch loss=2.77, Gen train loss=3.69, Disc batch loss=1.1, Disc train loss=0.589]  \n",
      "Epoch [37/64]: 100%|██████████| 1019/1019 [19:52<00:00,  1.17s/it, Gen batch loss=3.7, Gen train loss=3.59, Disc batch loss=0.557, Disc train loss=0.606] \n",
      "Epoch [38/64]: 100%|██████████| 1019/1019 [19:52<00:00,  1.17s/it, Gen batch loss=3.67, Gen train loss=3.66, Disc batch loss=0.674, Disc train loss=0.591]\n",
      "Epoch [39/64]: 100%|██████████| 1019/1019 [19:55<00:00,  1.17s/it, Gen batch loss=3.24, Gen train loss=3.62, Disc batch loss=0.468, Disc train loss=0.6]  \n",
      "Epoch [40/64]: 100%|██████████| 1019/1019 [19:57<00:00,  1.18s/it, Gen batch loss=3.72, Gen train loss=3.57, Disc batch loss=0.861, Disc train loss=0.592]\n",
      "Epoch [41/64]: 100%|██████████| 1019/1019 [19:54<00:00,  1.17s/it, Gen batch loss=4.28, Gen train loss=3.58, Disc batch loss=0.209, Disc train loss=0.616]\n",
      "Epoch [42/64]: 100%|██████████| 1019/1019 [19:52<00:00,  1.17s/it, Gen batch loss=3.5, Gen train loss=3.58, Disc batch loss=1.07, Disc train loss=0.596]  \n",
      "Epoch [43/64]: 100%|██████████| 1019/1019 [19:51<00:00,  1.17s/it, Gen batch loss=2.71, Gen train loss=3.52, Disc batch loss=0.879, Disc train loss=0.596]\n",
      "Epoch [44/64]: 100%|██████████| 1019/1019 [19:51<00:00,  1.17s/it, Gen batch loss=3.88, Gen train loss=3.51, Disc batch loss=0.679, Disc train loss=0.598]\n",
      "Epoch [45/64]: 100%|██████████| 1019/1019 [19:55<00:00,  1.17s/it, Gen batch loss=3.46, Gen train loss=3.48, Disc batch loss=0.499, Disc train loss=0.589]\n",
      "Epoch [46/64]: 100%|██████████| 1019/1019 [19:53<00:00,  1.17s/it, Gen batch loss=4.07, Gen train loss=3.54, Disc batch loss=1.06, Disc train loss=0.584] \n",
      "Epoch [47/64]: 100%|██████████| 1019/1019 [19:52<00:00,  1.17s/it, Gen batch loss=4.16, Gen train loss=3.46, Disc batch loss=0.181, Disc train loss=0.582]\n",
      "Epoch [48/64]:  29%|██▊       | 291/1019 [05:41<14:14,  1.17s/it, Gen batch loss=2.6, Gen train loss=3.37, Disc batch loss=0.753, Disc train loss=0.607] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator_G\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator_G\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[43mgenerator_H\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator_H\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdiscriminator_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscriminator_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdiscriminator_Y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscriminator_Y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m             \u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m             \u001b[49m\u001b[43ml1_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m             \u001b[49m\u001b[43mcycle_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCYCLE_LAMBDA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m             \u001b[49m\u001b[43mgen_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdisc_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisc_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m             \u001b[49m\u001b[43mgen_scaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_scaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdisc_scaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisc_scaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m             \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m             \u001b[49m\u001b[43mgenerator_G_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGENERATOR_G_SAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m             \u001b[49m\u001b[43mgenerator_H_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGENERATOR_H_SAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdiscriminator_X_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDISCRIMINATOR_X_SAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdiscriminator_Y_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDISCRIMINATOR_Y_SAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m             \u001b[49m\u001b[43mresult_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRESULT_SAVE_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Ganesh\\Amrita\\Subjects\\Sem 5\\Deep Learning\\My works\\GAN\\CycleGAN\\trainer.py:161\u001b[0m, in \u001b[0;36mtrain_models\u001b[1;34m(generator_G, generator_H, discriminator_X, discriminator_Y, dataloader, mse_loss, l1_loss, cycle_lambda, gen_optimizer, disc_optimizer, gen_scaler, disc_scaler, device, NUM_EPOCHS, generator_G_path, generator_H_path, discriminator_X_path, discriminator_Y_path, result_path)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m t:\n\u001b[0;32m    151\u001b[0m     disc_batch_loss \u001b[38;5;241m=\u001b[39m train_discriminator(generator_G\u001b[38;5;241m=\u001b[39mgenerator_G, \n\u001b[0;32m    152\u001b[0m                                           generator_H\u001b[38;5;241m=\u001b[39mgenerator_H, \n\u001b[0;32m    153\u001b[0m                                           discriminator_X\u001b[38;5;241m=\u001b[39mdiscriminator_X, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    158\u001b[0m                                           scaler\u001b[38;5;241m=\u001b[39mdisc_scaler, \n\u001b[0;32m    159\u001b[0m                                           device\u001b[38;5;241m=\u001b[39mdevice, )\n\u001b[1;32m--> 161\u001b[0m     gen_batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator_G\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator_G\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mgenerator_H\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator_H\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mdiscriminator_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscriminator_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mdiscriminator_Y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscriminator_Y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43ml1_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mcycle_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcycle_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_scaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m     gen_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m gen_batch_loss\n\u001b[0;32m    174\u001b[0m     disc_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m disc_batch_loss\n",
      "File \u001b[1;32mf:\\Ganesh\\Amrita\\Subjects\\Sem 5\\Deep Learning\\My works\\GAN\\CycleGAN\\trainer.py:54\u001b[0m, in \u001b[0;36mtrain_generator\u001b[1;34m(generator_G, generator_H, discriminator_X, discriminator_Y, batch, mse_loss, l1_loss, cycle_lambda, optimizer, scaler, device)\u001b[0m\n\u001b[0;32m     52\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     53\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 54\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m real_apple, real_orange, fake_apple, fake_orange, fake_apple_labels, fake_orange_labels, fake_apple_preds, fake_orange_preds, \n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TorchEnv2\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:453\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    451\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 453\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TorchEnv2\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:350\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    344\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    349\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    351\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TorchEnv2\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:350\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    344\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    349\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    351\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_models(generator_G=generator_G,\n",
    "             generator_H=generator_H,\n",
    "             discriminator_X=discriminator_X,\n",
    "             discriminator_Y=discriminator_Y,\n",
    "             dataloader=train_dataloader,\n",
    "             mse_loss=mse_loss,\n",
    "             l1_loss=l1_loss,\n",
    "             cycle_lambda=CYCLE_LAMBDA,\n",
    "             gen_optimizer=gen_optimizer,\n",
    "             disc_optimizer=disc_optimizer,\n",
    "             gen_scaler=gen_scaler,\n",
    "             disc_scaler=disc_scaler,\n",
    "             device=device,\n",
    "             NUM_EPOCHS=NUM_EPOCHS,\n",
    "             generator_G_path=GENERATOR_G_SAVE_PATH,\n",
    "             generator_H_path=GENERATOR_H_SAVE_PATH,\n",
    "             discriminator_X_path=DISCRIMINATOR_X_SAVE_PATH,\n",
    "             discriminator_Y_path=DISCRIMINATOR_Y_SAVE_PATH,\n",
    "             result_path=RESULT_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models\n",
    "\n",
    "torch.save(obj=generator_G.state_dict(), f=GENERATOR_G_SAVE_PATH)\n",
    "torch.save(obj=generator_H.state_dict(), f=GENERATOR_H_SAVE_PATH)\n",
    "torch.save(obj=discriminator_X.state_dict(), f=DISCRIMINATOR_X_SAVE_PATH)\n",
    "torch.save(obj=discriminator_Y.state_dict(), f=DISCRIMINATOR_Y_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
